{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary & Semantic segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today:\n",
    "- segmentation metrics\n",
    "- simple unet\n",
    "- catalyst config & segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "[simple explanation](https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2)\n",
    "- Pixelwise accuracy (bad for imbalanced dataset as classification accuracy)\n",
    "- IoU = Area of intersection(A, B) / Area of union(A, B) (for binary masks of given class C)\n",
    "- Dice = 2 * Area of intersection(A, B) / (Area(A)+Area(B)) (for binary masks of given class C)\n",
    "\n",
    "[iou vs dice](https://stats.stackexchange.com/questions/273537/f1-dice-score-vs-iou/276144#276144)\n",
    "- IoU and Dice are positively correlated (which means for same A and B, dice(model1) < dice(model2) <-> IoU(model1) < IoU(model2))\n",
    "- for multiple instances: \"Suppose for example that the vast majority of the inferences are moderately better with classifier A than B, but some of them of them are significantly worse using classifier A. It may be the case then that the F metric favors classifier A while the IoU metric favors classifier B.\"\n",
    "\n",
    "IoU returns measure **closer to worst-performing** (similar to L2)\n",
    "\n",
    "Dice returns **closer to mean performance** (similar to L1)\n",
    "\n",
    "Alternative name for dice is f-measure (f1-score)\n",
    "\n",
    "Alternative name for IoU is Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "outputs = torch.tensor([\n",
    "    [\n",
    "        [0, 0, 0, 1],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 1, 0, 1]\n",
    "    ]\n",
    "])[:, None]\n",
    "targets = torch.tensor([\n",
    "    [\n",
    "        [0, 0, 0, 1],\n",
    "        [1, 1, 0, 1],\n",
    "        [1, 1, 0, 1]\n",
    "    ]\n",
    "])[:, None]\n",
    "outputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_eq(a, b, eps=1e-4):\n",
    "    return ((a-b).abs().sum() < eps).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "Implement IoU, Dice and pixelwise accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(\n",
    "        outputs,\n",
    "        targets\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the accuracy for 2 tensors of same shape\n",
    "    \n",
    "    accuracy = n_correct / n_total\n",
    "    \"\"\"\n",
    "    # TODO(students)\n",
    "    accuracy = ?\n",
    "    return accuracy\n",
    "\n",
    "accuracy_metric = accuracy(outputs, targets)\n",
    "assert approx_eq(accuracy_metric, 0.9167)\n",
    "accuracy_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.utils import get_activation_fn\n",
    "\n",
    "def dice(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,\n",
    "    activation: str = \"none\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the dice metric\n",
    "    \n",
    "    dice = 2 * intersection / (union + intersection)\n",
    "\n",
    "    Args:\n",
    "        outputs (tensor):  A tensor of predicted elements\n",
    "        targets (tensor): A tensor of elements that are to be predicted\n",
    "        eps (float): epsilon\n",
    "        threshold (float): threshold for outputs binarization\n",
    "        activation (str): An torch.nn activation applied to the outputs.\n",
    "            Must be one of [\"none\", \"Sigmoid\", \"Softmax2d\"]\n",
    "\n",
    "    Returns:\n",
    "        double:  Dice score\n",
    "    \"\"\"\n",
    "    activation_fn = get_activation_fn(activation)\n",
    "    outputs = activation_fn(outputs)\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold)\n",
    "        \n",
    "    outputs = outputs.float()\n",
    "    targets = targets.float()\n",
    "    # TODO(students)\n",
    "    dice = ?\n",
    "\n",
    "    return dice\n",
    "\n",
    "dice_metric = dice(outputs, targets)\n",
    "assert approx_eq(dice_metric, 0.9231)\n",
    "dice_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,\n",
    "    activation: str = \"none\"\n",
    "):\n",
    "    \"\"\"\n",
    "    iou = intersection / union\n",
    "    \n",
    "    Args:\n",
    "        outputs (torch.Tensor): A list of predicted elements\n",
    "        targets (torch.Tensor):  A list of elements that are to be predicted\n",
    "        eps (float): epsilon to avoid zero division\n",
    "        threshold (float): threshold for outputs binarization\n",
    "        activation (str): An torch.nn activation applied to the outputs.\n",
    "            Must be one of [\"none\", \"Sigmoid\", \"Softmax2d\"]\n",
    "\n",
    "    Returns:\n",
    "        float: IoU (Jaccard) score\n",
    "    \"\"\"\n",
    "    activation_fn = get_activation_fn(activation)\n",
    "    outputs = activation_fn(outputs)\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold)\n",
    "        \n",
    "    outputs = outputs.float()\n",
    "    targets = targets.float()\n",
    "\n",
    "    # TODO(students)\n",
    "    iou = ?\n",
    "\n",
    "    return iou\n",
    "\n",
    "iou_metric = iou(outputs, targets)\n",
    "assert approx_eq(iou_metric, 0.8571)\n",
    "iou_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = ConvBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        # p2d = (1, 1, 2, 2) pads last dim by (1, 1) and 2nd to last by (2, 2)\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = ConvBlock(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear=True)\n",
    "        self.up2 = Up(512, 128, bilinear=True)\n",
    "        self.up3 = Up(256, 64, bilinear=True)\n",
    "        self.up4 = Up(128, 64, bilinear=True)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "    \n",
    "UNet(3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalyst again\n",
    "\n",
    "You will be working with [this](http://artelab.dista.uninsubria.it/downloads/datasets/barcode/medium_barcode_1d/medium_barcode_1d.html) dataset. You can also try PascalVoc2012.\n",
    "\n",
    "1. unzip ./data/Artelab.zip\n",
    "2. sh ./scripts/prepare_data.sh\n",
    "3. catalyst-dl run -C /path/to/config --logdir /path/to/logdir --baselogdir /path/to/baselogdir\n",
    "4. cat runs.sh | catalyst-parallel-run <n_gpus>\n",
    "\n",
    "[catalyst explained (video)](https://youtu.be/SGawkIjBoGE?t=561)\n",
    "\n",
    "[catalyst explained (slides)](https://docs.google.com/presentation/d/10dJqTGEPxk_gYKCZZdFqHHhuPUwwKNYdRhvuNphpy5E/edit#slide=id.g5eb386574d_0_155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
